{"cells":[{"cell_type":"code","execution_count":null,"id":"a7ebbf52-fec8-4bf2-afd6-cb7ca734a1b4","metadata":{"id":"a7ebbf52-fec8-4bf2-afd6-cb7ca734a1b4","outputId":"374a7dba-b737-446a-ef6e-4cda8aa5b519"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'Q-Align' already exists and is not an empty directory.\n","/workspace/Q-Align\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n","  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"]},{"name":"stdout","output_type":"stream","text":["Obtaining file:///workspace/Q-Align\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n","\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1)\n","Requirement already satisfied: torchvision==0.15.2 in /usr/local/lib/python3.10/dist-packages (0.15.2)\n","Requirement already satisfied: transformers==4.36.1 in /usr/local/lib/python3.10/dist-packages (4.36.1)\n","Requirement already satisfied: tokenizers==0.15.0 in /usr/local/lib/python3.10/dist-packages (0.15.0)\n","Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: shortuuid in /usr/local/lib/python3.10/dist-packages (1.0.13)\n","Requirement already satisfied: accelerate==0.21.0 in /usr/local/lib/python3.10/dist-packages (0.21.0)\n","Requirement already satisfied: peft==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: bitsandbytes==0.41.0 in /usr/local/lib/python3.10/dist-packages (0.41.0)\n","Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (1.10.17)\n","Requirement already satisfied: markdown2[all] in /usr/local/lib/python3.10/dist-packages (2.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.1)\n","Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: gradio==3.35.2 in /usr/local/lib/python3.10/dist-packages (3.35.2)\n","Requirement already satisfied: gradio-client==0.2.9 in /usr/local/lib/python3.10/dist-packages (0.2.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Requirement already satisfied: httpx==0.24.0 in /usr/local/lib/python3.10/dist-packages (0.24.0)\n","Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.30.1)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.111.1)\n","Requirement already satisfied: icecream in /usr/local/lib/python3.10/dist-packages (2.1.3)\n","Requirement already satisfied: einops==0.6.1 in /usr/local/lib/python3.10/dist-packages (0.6.1)\n","Requirement already satisfied: einops-exts==0.0.4 in /usr/local/lib/python3.10/dist-packages (0.0.4)\n","Requirement already satisfied: timm==0.6.13 in /usr/local/lib/python3.10/dist-packages (0.6.13)\n","Requirement already satisfied: decord in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.14.0)\n","Requirement already satisfied: deepspeed==0.9.5 in /usr/local/lib/python3.10/dist-packages (0.9.5)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (5.9.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (6.0.1)\n","Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.9.5) (3.1.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.9.5) (9.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.9.5) (4.66.4)\n","Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (24.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (3.9.5)\n","Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (5.3.0)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (0.3.2)\n","Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (0.23.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (3.1.2)\n","Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2) (2.2.0)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (2.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (3.9.1)\n","Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (0.3.3)\n","Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (3.10.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (2.2.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (9.3.0)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (0.25.1)\n","Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (2.16.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (0.0.9)\n","Requirement already satisfied: semantic-version in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (2.10.0)\n","Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (12.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.2.9) (2024.6.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.2.9) (4.12.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0) (2022.12.7)\n","Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0) (0.17.3)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0) (3.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0) (1.3.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (0.4.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.1) (2024.5.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (68.2.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.41.3)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n","Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.37.2)\n","Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.4)\n","Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.2.0)\n","Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from icecream) (0.4.6)\n","Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.0.1)\n","Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.4.1)\n","Requirement already satisfied: wavedrom in /usr/local/lib/python3.10/dist-packages (from markdown2[all]) (2.0.3.post3)\n","Requirement already satisfied: latex2mathml in /usr/local/lib/python3.10/dist-packages (from markdown2[all]) (3.77.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (2.1.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.13)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (3.11.0)\n","Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.27.2)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2) (0.12.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n","Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (2.6.1)\n","Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0) (4.0.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2) (0.1.2)\n","Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2) (2.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.35.2) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.35.2) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.35.2) (2024.1)\n","Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.19.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.22.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2) (4.0.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.35.2) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->gradio==3.35.2) (2.4.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n","Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/dist-packages (from wavedrom->markdown2[all]) (1.4.3)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx==0.24.0) (1.1.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2) (0.12.0)\n","Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2) (1.0.3)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n","Checking if build backend supports build_editable ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: q_align\n","  Building editable for q_align (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for q_align: filename=q_align-1.2.0-0.editable-py3-none-any.whl size=7984 sha256=f608ed61b463e639653627463b7ce00ae11b9c2459311f03185e145ff1c581c4\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-s9h64smn/wheels/6f/99/0b/dd230991014892200c16f9bfed662d47ee4b125637a86ed7ae\n","Successfully built q_align\n","Installing collected packages: q_align\n","  Attempting uninstall: q_align\n","    Found existing installation: q_align 1.2.0\n","    Uninstalling q_align-1.2.0:\n","      Successfully uninstalled q_align-1.2.0\n","Successfully installed q_align-1.2.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n","Requirement already satisfied: flash_attn in /usr/local/lib/python3.10/dist-packages (2.6.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash_attn) (2.0.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash_attn) (0.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.9.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash_attn) (68.2.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash_attn) (0.41.3)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash_attn) (3.30.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash_attn) (18.1.8)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash_attn) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash_attn) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"]}],"source":["!git clone https://github.com/Q-Future/Q-Align.git\n","%cd Q-Align\n","!pip install -e \".[train]\"\n","!pip install flash_attn --no-build-isolation"]},{"cell_type":"code","execution_count":null,"id":"11d21e5a-3e9e-43ec-a8f0-ebb676c986dc","metadata":{"id":"11d21e5a-3e9e-43ec-a8f0-ebb676c986dc","outputId":"0bb0137a-74bd-449c-a7df-4679960570a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: deepspeed in /usr/local/lib/python3.10/dist-packages (0.9.5)\n","Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed) (3.1.0)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.11.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.24.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.6)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n","Requirement already satisfied: pydantic<2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.10.17)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->deepspeed) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deepspeed) (68.2.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deepspeed) (0.41.3)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (3.30.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (18.1.8)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install deepspeed"]},{"cell_type":"code","execution_count":null,"id":"69e2a704-d3f6-475c-964f-862c2c2cb2cd","metadata":{"id":"69e2a704-d3f6-475c-964f-862c2c2cb2cd"},"outputs":[],"source":["# Copy JSON file\n","!cp /workspace/train_split_1.json /workspace/Q-Align/playground/data/ft/\n","\n","# Create directory for video data\n","!mkdir -p /workspace/video_data\n","\n","# Copy video files\n","!cp /workspace/*.mp4 /workspace/video_data/\n","# If you have GIF files, use this command as well:\n","# !cp /content/drive/MyDrive/Q-Align_data/*.gif /content/video_data/"]},{"cell_type":"code","execution_count":null,"id":"cd04952c-ecd8-48a0-bbe3-c97002cfe911","metadata":{"id":"cd04952c-ecd8-48a0-bbe3-c97002cfe911","outputId":"f0cfaa5e-2a93-48cc-e37c-3a1a80c3d159"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 36\n","drwxr-xr-x 2 root root 4096 Jul 16 15:54 agi\n","drwxr-xr-x 2 root root 4096 Jul 16 15:54 agiqa3k\n","drwxr-xr-x 2 root root 4096 Jul 16 15:54 cgi\n","drwxr-xr-x 2 root root 4096 Jul 16 15:54 csiq\n","drwxr-xr-x 2 root root 4096 Jul 16 15:54 live\n","drwxr-xr-x 2 root root 4096 Jul 16 15:54 livec\n","drwxr-xr-x 2 root root   69 Jul 16 15:54 maxwell\n","-rw-r--r-- 1 root root 8887 Jul 18 00:12 train_split_1.json\n","total 32828\n","-rw-r--r-- 1 root root 1367318 Jul 18 00:12  Anatomy_Bad.mp4\n","-rw-r--r-- 1 root root 1730556 Jul 18 00:12  Beach_Good.mp4\n","-rw-r--r-- 1 root root  710597 Jul 18 00:12  BeachwithProduct_Good.mp4\n","-rw-r--r-- 1 root root 3021685 Jul 18 00:12  Car_Moving_Backlwards.mp4\n","-rw-r--r-- 1 root root  826721 Jul 18 00:12  ExtraHand_Bad.mp4\n","-rw-r--r-- 1 root root  995400 Jul 18 00:12  EyesDistorted_Bad.mp4\n","-rw-r--r-- 1 root root  238587 Jul 18 00:12  FLowers_anatomy.mp4\n","-rw-r--r-- 1 root root 1077436 Jul 18 00:12  Face_Bad.mp4\n","-rw-r--r-- 1 root root 3294863 Jul 18 00:12  Girl_Good.mp4\n","-rw-r--r-- 1 root root  516416 Jul 18 00:12  HeadAndShoulder_Good.mp4\n","-rw-r--r-- 1 root root  930190 Jul 18 00:12  Human_Moving_Backward.mp4\n","-rw-r--r-- 1 root root 1101616 Jul 18 00:12  Light1_Bad.mp4\n","-rw-r--r-- 1 root root  958046 Jul 18 00:12  Mask_good.mp4\n","-rw-r--r-- 1 root root  627003 Jul 18 00:12  Plum_Good.mp4\n","-rw-r--r-- 1 root root 1101616 Jul 18 00:12  ShampooBottle_Bad.mp4\n","-rw-r--r-- 1 root root  717811 Jul 18 00:12  Smile_Good.mp4\n","-rw-r--r-- 1 root root  838754 Jul 18 00:12  SmillingFace_Good.mp4\n","-rw-r--r-- 1 root root  146131 Jul 18 00:12  SpiderMan_Bad.mp4\n","-rw-r--r-- 1 root root  665636 Jul 18 00:12  Sunrise_Good.mp4\n","-rw-r--r-- 1 root root 1048281 Jul 18 00:12  Water_Good.mp4\n","-rw-r--r-- 1 root root 1226843 Jul 18 00:12  Waterfalling_Decent.mp4\n","-rw-r--r-- 1 root root 1154239 Jul 18 00:12  WomanEyeDistortion_Bad.mp4\n","-rw-r--r-- 1 root root 1410517 Jul 18 00:12  WomanShampoo_Decent.mp4\n","-rw-r--r-- 1 root root  710597 Jul 18 00:12  WomenwithProduct_Good.mp4\n","-rw-r--r-- 1 root root 1825339 Jul 18 00:12  WorkingOut_Bad.mp4\n","-rw-r--r-- 1 root root 1270426 Jul 18 00:12 'anatomy_bad(1).mp4'\n","-rw-r--r-- 1 root root  926607 Jul 18 00:12  light_bad.mp4\n","-rw-r--r-- 1 root root 1033072 Jul 18 00:12  water_bad.mp4\n","-rw-r--r-- 1 root root  944233 Jul 18 00:12  water_girl_bad.mp4\n","-rw-r--r-- 1 root root 1135137 Jul 18 00:12  women_Very_bad.mp4\n"]}],"source":["!ls -l /workspace/Q-Align/playground/data/ft/\n","!ls -l /workspace/video_data/"]},{"cell_type":"code","execution_count":null,"id":"615a619b-31d3-4c33-aa38-55196cde03b1","metadata":{"id":"615a619b-31d3-4c33-aa38-55196cde03b1","outputId":"6d4aa076-bb5e-404a-879f-1aea9e98bd8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting scripts/my_videos_lora.sh\n"]}],"source":["%%writefile scripts/my_videos_lora.sh\n","#!/bin/bash\n","\n","# Create input file with choice\n","echo \"2\" > input.txt\n","export WANDB_API_KEY=\"d748b17184ce7ec9c05419bb670fbda0fd136a13\"\n","\n","wandb login $WANDB_API_KEY\n","\n","# Run the script with input redirection\n","deepspeed q_align/train/train_mem.py < input.txt \\\n","    --deepspeed ./scripts/zero3.json \\\n","    --model_name_or_path q-future/one-align \\\n","    --version v1 \\\n","    --data_path /workspace/Q-Align/playground/data/ft/train_split_1.json \\\n","    --image_folder /workspace/video_data \\\n","    --bf16 True \\\n","    --output_dir /workspace/Q-Align/checkpoints/ \\\n","    --num_train_epochs 1 \\\n","    --per_device_train_batch_size 1 \\\n","    --per_device_eval_batch_size 1 \\\n","    --gradient_accumulation_step 4 \\\n","    --evaluation_strategy \"no\" \\\n","    --save_strategy \"steps\" \\\n","    --save_steps 50000 \\\n","    --save_total_limit 1 \\\n","    --learning_rate 2e-5 \\\n","    --weight_decay 0. \\\n","    --warmup_ratio 0.03 \\\n","    --lr_scheduler_type \"cosine\" \\\n","    --logging_steps 1 \\\n","    --tf32 True \\\n","    --model_max_length 2048 \\\n","    --gradient_checkpointing True \\\n","    --dataloader_num_workers 4 \\\n","    --lazy_preprocess True \\\n","    --report_to wandb\n"]},{"cell_type":"markdown","id":"fe7c991d-00a0-47ee-82a2-b3f33defd81e","metadata":{"id":"fe7c991d-00a0-47ee-82a2-b3f33defd81e"},"source":[]},{"cell_type":"code","execution_count":null,"id":"92e3c21d-2df6-4623-ac92-d9f2ad54df67","metadata":{"id":"92e3c21d-2df6-4623-ac92-d9f2ad54df67","outputId":"6fcada41-8531-46ca-d86a-41458fabafb4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","[2024-07-18 00:20:31,397] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-07-18 00:20:33,201] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n","[2024-07-18 00:20:33,201] [INFO] [runner.py:555:main] cmd = /usr/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None q_align/train/train_mem.py --deepspeed ./scripts/zero3.json --model_name_or_path q-future/one-align --version v1 --data_path /workspace/Q-Align/playground/data/ft/train_split_1.json --image_folder /workspace/video_data --bf16 True --output_dir /workspace/Q-Align/checkpoints/ --num_train_epochs 1 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_step 4 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb\n","[2024-07-18 00:20:34,222] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.15.5-1+cuda11.8\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.15.5-1\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.15.5-1\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.15.5-1+cuda11.8\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.15.5-1\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1]}\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:163:main] dist_world_size=2\n","[2024-07-18 00:20:35,834] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1\n","[2024-07-18 00:20:38,247] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-07-18 00:20:38,262] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-07-18 00:20:38,780] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n","[2024-07-18 00:20:38,780] [INFO] [comm.py:594:init_distributed] cdb=None\n","[2024-07-18 00:20:38,780] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n","[2024-07-18 00:20:38,805] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n","[2024-07-18 00:20:38,805] [INFO] [comm.py:594:init_distributed] cdb=None\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Instantiating LlamaAttention without passing `layer_idx` is not recommended and will to errors during the forward call, if caching is used. Please make sure to provide a `layer_idx` when creating this class.\n","Instantiating LlamaAttention without passing `layer_idx` is not recommended and will to errors during the forward call, if caching is used. Please make sure to provide a `layer_idx` when creating this class.\n","[2024-07-18 00:20:41,554] [WARNING] [partition_parameters.py:836:_post_init_method] param `cls_token` in MplugOwlVisionEmbeddings not on GPU so was not broadcasted from rank 0\n","[2024-07-18 00:20:41,554] [WARNING] [partition_parameters.py:836:_post_init_method] param `position_embedding` in MplugOwlVisionEmbeddings not on GPU so was not broadcasted from rank 0\n","[2024-07-18 00:20:42,535] [WARNING] [partition_parameters.py:836:_post_init_method] param `query_embeds` in MplugOwlVisualAbstractorModel not on GPU so was not broadcasted from rank 0\n","[2024-07-18 00:20:42,536] [WARNING] [partition_parameters.py:836:_post_init_method] param `vit_eos` in MplugOwlVisualAbstractorModel not on GPU so was not broadcasted from rank 0\n","[2024-07-18 00:20:43,099] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 11.42B parameters\n","Loading checkpoint shards: 100%|██████████████████| 2/2 [00:12<00:00,  6.24s/it]\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","MPLUGOwl2Config {\n","  \"_name_or_path\": \"q-future/one-align\",\n","  \"architectures\": [\n","    \"MPLUGOwl2LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"q-future/one-align--configuration_mplug_owl2.MPLUGOwl2Config\",\n","    \"AutoModel\": \"q-future/one-align--modeling_mplug_owl2.MPLUGOwl2LlamaForCausalLM\",\n","    \"AutoModelForCausalLM\": \"q-future/one-align--modeling_mplug_owl2.MPLUGOwl2LlamaForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2,\n","  \"freeze_vision_model\": false,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 4096,\n","  \"image_aspect_ratio\": \"pad\",\n","  \"image_grid_pinpoints\": null,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 11008,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"mplug_owl2\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.36.1\",\n","  \"tune_visual_abstractor\": true,\n","  \"use_cache\": true,\n","  \"visual_abstractor_lr\": null,\n","  \"visual_config\": {\n","    \"visual_abstractor\": {\n","      \"_name_or_path\": \"\",\n","      \"add_cross_attention\": false,\n","      \"architectures\": null,\n","      \"attention_probs_dropout_prob\": 0.0,\n","      \"bad_words_ids\": null,\n","      \"begin_suppress_tokens\": null,\n","      \"bos_token_id\": null,\n","      \"chunk_size_feed_forward\": 0,\n","      \"cross_attention_hidden_size\": null,\n","      \"decoder_start_token_id\": null,\n","      \"diversity_penalty\": 0.0,\n","      \"do_sample\": false,\n","      \"early_stopping\": false,\n","      \"encoder_hidden_size\": 1024,\n","      \"encoder_no_repeat_ngram_size\": 0,\n","      \"eos_token_id\": null,\n","      \"exponential_decay_length_penalty\": null,\n","      \"finetuning_task\": null,\n","      \"forced_bos_token_id\": null,\n","      \"forced_eos_token_id\": null,\n","      \"grid_size\": 32,\n","      \"hidden_size\": 1024,\n","      \"id2label\": {\n","        \"0\": \"LABEL_0\",\n","        \"1\": \"LABEL_1\"\n","      },\n","      \"initializer_range\": 0.02,\n","      \"intermediate_size\": 2816,\n","      \"is_decoder\": false,\n","      \"is_encoder_decoder\": false,\n","      \"label2id\": {\n","        \"LABEL_0\": 0,\n","        \"LABEL_1\": 1\n","      },\n","      \"layer_norm_eps\": 1e-06,\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 20,\n","      \"min_length\": 0,\n","      \"model_type\": \"mplug_owl_visual_abstract\",\n","      \"no_repeat_ngram_size\": 0,\n","      \"num_attention_heads\": 16,\n","      \"num_beam_groups\": 1,\n","      \"num_beams\": 1,\n","      \"num_hidden_layers\": 6,\n","      \"num_learnable_queries\": 64,\n","      \"num_return_sequences\": 1,\n","      \"output_attentions\": false,\n","      \"output_hidden_states\": false,\n","      \"output_scores\": false,\n","      \"pad_token_id\": null,\n","      \"prefix\": null,\n","      \"problem_type\": null,\n","      \"pruned_heads\": {},\n","      \"remove_invalid_values\": false,\n","      \"repetition_penalty\": 1.0,\n","      \"return_dict\": true,\n","      \"return_dict_in_generate\": false,\n","      \"sep_token_id\": null,\n","      \"suppress_tokens\": null,\n","      \"task_specific_params\": null,\n","      \"temperature\": 1.0,\n","      \"tf_legacy_loss\": false,\n","      \"tie_encoder_decoder\": false,\n","      \"tie_word_embeddings\": true,\n","      \"tokenizer_class\": null,\n","      \"top_k\": 50,\n","      \"top_p\": 1.0,\n","      \"torch_dtype\": null,\n","      \"torchscript\": false,\n","      \"transformers_version\": \"4.28.1\",\n","      \"typical_p\": 1.0,\n","      \"use_bfloat16\": false\n","    },\n","    \"visual_model\": {\n","      \"_name_or_path\": \"\",\n","      \"add_cross_attention\": false,\n","      \"architectures\": null,\n","      \"attention_dropout\": 0.0,\n","      \"bad_words_ids\": null,\n","      \"begin_suppress_tokens\": null,\n","      \"bos_token_id\": null,\n","      \"chunk_size_feed_forward\": 0,\n","      \"cross_attention_hidden_size\": null,\n","      \"decoder_start_token_id\": null,\n","      \"diversity_penalty\": 0.0,\n","      \"do_sample\": false,\n","      \"early_stopping\": false,\n","      \"encoder_no_repeat_ngram_size\": 0,\n","      \"eos_token_id\": null,\n","      \"exponential_decay_length_penalty\": null,\n","      \"finetuning_task\": null,\n","      \"forced_bos_token_id\": null,\n","      \"forced_eos_token_id\": null,\n","      \"hidden_act\": \"quick_gelu\",\n","      \"hidden_size\": 1024,\n","      \"id2label\": {\n","        \"0\": \"LABEL_0\",\n","        \"1\": \"LABEL_1\"\n","      },\n","      \"image_size\": 448,\n","      \"initializer_factor\": 1.0,\n","      \"initializer_range\": 0.02,\n","      \"intermediate_size\": 4096,\n","      \"is_decoder\": false,\n","      \"is_encoder_decoder\": false,\n","      \"label2id\": {\n","        \"LABEL_0\": 0,\n","        \"LABEL_1\": 1\n","      },\n","      \"layer_norm_eps\": 1e-06,\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 20,\n","      \"min_length\": 0,\n","      \"model_type\": \"mplug_owl_vision_model\",\n","      \"no_repeat_ngram_size\": 0,\n","      \"num_attention_heads\": 16,\n","      \"num_beam_groups\": 1,\n","      \"num_beams\": 1,\n","      \"num_channels\": 3,\n","      \"num_hidden_layers\": 24,\n","      \"num_return_sequences\": 1,\n","      \"output_attentions\": false,\n","      \"output_hidden_states\": false,\n","      \"output_scores\": false,\n","      \"pad_token_id\": null,\n","      \"patch_size\": 14,\n","      \"prefix\": null,\n","      \"problem_type\": null,\n","      \"projection_dim\": 768,\n","      \"pruned_heads\": {},\n","      \"remove_invalid_values\": false,\n","      \"repetition_penalty\": 1.0,\n","      \"return_dict\": true,\n","      \"return_dict_in_generate\": false,\n","      \"sep_token_id\": null,\n","      \"suppress_tokens\": null,\n","      \"task_specific_params\": null,\n","      \"temperature\": 1.0,\n","      \"tf_legacy_loss\": false,\n","      \"tie_encoder_decoder\": false,\n","      \"tie_word_embeddings\": true,\n","      \"tokenizer_class\": null,\n","      \"top_k\": 50,\n","      \"top_p\": 1.0,\n","      \"torch_dtype\": null,\n","      \"torchscript\": false,\n","      \"transformers_version\": \"4.28.1\",\n","      \"typical_p\": 1.0,\n","      \"use_bfloat16\": false,\n","      \"use_flash_attn\": false\n","    }\n","  },\n","  \"vocab_size\": 32000\n","}\n","\n","False\n","True\n","/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n","  warnings.warn(\n","Loading checkpoint shards: 100%|██████████████████| 2/2 [00:13<00:00,  6.80s/it]\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","MPLUGOwl2Config {\n","  \"_name_or_path\": \"q-future/one-align\",\n","  \"architectures\": [\n","    \"MPLUGOwl2LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"q-future/one-align--configuration_mplug_owl2.MPLUGOwl2Config\",\n","    \"AutoModel\": \"q-future/one-align--modeling_mplug_owl2.MPLUGOwl2LlamaForCausalLM\",\n","    \"AutoModelForCausalLM\": \"q-future/one-align--modeling_mplug_owl2.MPLUGOwl2LlamaForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2,\n","  \"freeze_vision_model\": false,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 4096,\n","  \"image_aspect_ratio\": \"pad\",\n","  \"image_grid_pinpoints\": null,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 11008,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"mplug_owl2\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.36.1\",\n","  \"tune_visual_abstractor\": true,\n","  \"use_cache\": true,\n","  \"visual_abstractor_lr\": null,\n","  \"visual_config\": {\n","    \"visual_abstractor\": {\n","      \"_name_or_path\": \"\",\n","      \"add_cross_attention\": false,\n","      \"architectures\": null,\n","      \"attention_probs_dropout_prob\": 0.0,\n","      \"bad_words_ids\": null,\n","      \"begin_suppress_tokens\": null,\n","      \"bos_token_id\": null,\n","      \"chunk_size_feed_forward\": 0,\n","      \"cross_attention_hidden_size\": null,\n","      \"decoder_start_token_id\": null,\n","      \"diversity_penalty\": 0.0,\n","      \"do_sample\": false,\n","      \"early_stopping\": false,\n","      \"encoder_hidden_size\": 1024,\n","      \"encoder_no_repeat_ngram_size\": 0,\n","      \"eos_token_id\": null,\n","      \"exponential_decay_length_penalty\": null,\n","      \"finetuning_task\": null,\n","      \"forced_bos_token_id\": null,\n","      \"forced_eos_token_id\": null,\n","      \"grid_size\": 32,\n","      \"hidden_size\": 1024,\n","      \"id2label\": {\n","        \"0\": \"LABEL_0\",\n","        \"1\": \"LABEL_1\"\n","      },\n","      \"initializer_range\": 0.02,\n","      \"intermediate_size\": 2816,\n","      \"is_decoder\": false,\n","      \"is_encoder_decoder\": false,\n","      \"label2id\": {\n","        \"LABEL_0\": 0,\n","        \"LABEL_1\": 1\n","      },\n","      \"layer_norm_eps\": 1e-06,\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 20,\n","      \"min_length\": 0,\n","      \"model_type\": \"mplug_owl_visual_abstract\",\n","      \"no_repeat_ngram_size\": 0,\n","      \"num_attention_heads\": 16,\n","      \"num_beam_groups\": 1,\n","      \"num_beams\": 1,\n","      \"num_hidden_layers\": 6,\n","      \"num_learnable_queries\": 64,\n","      \"num_return_sequences\": 1,\n","      \"output_attentions\": false,\n","      \"output_hidden_states\": false,\n","      \"output_scores\": false,\n","      \"pad_token_id\": null,\n","      \"prefix\": null,\n","      \"problem_type\": null,\n","      \"pruned_heads\": {},\n","      \"remove_invalid_values\": false,\n","      \"repetition_penalty\": 1.0,\n","      \"return_dict\": true,\n","      \"return_dict_in_generate\": false,\n","      \"sep_token_id\": null,\n","      \"suppress_tokens\": null,\n","      \"task_specific_params\": null,\n","      \"temperature\": 1.0,\n","      \"tf_legacy_loss\": false,\n","      \"tie_encoder_decoder\": false,\n","      \"tie_word_embeddings\": true,\n","      \"tokenizer_class\": null,\n","      \"top_k\": 50,\n","      \"top_p\": 1.0,\n","      \"torch_dtype\": null,\n","      \"torchscript\": false,\n","      \"transformers_version\": \"4.28.1\",\n","      \"typical_p\": 1.0,\n","      \"use_bfloat16\": false\n","    },\n","    \"visual_model\": {\n","      \"_name_or_path\": \"\",\n","      \"add_cross_attention\": false,\n","      \"architectures\": null,\n","      \"attention_dropout\": 0.0,\n","      \"bad_words_ids\": null,\n","      \"begin_suppress_tokens\": null,\n","      \"bos_token_id\": null,\n","      \"chunk_size_feed_forward\": 0,\n","      \"cross_attention_hidden_size\": null,\n","      \"decoder_start_token_id\": null,\n","      \"diversity_penalty\": 0.0,\n","      \"do_sample\": false,\n","      \"early_stopping\": false,\n","      \"encoder_no_repeat_ngram_size\": 0,\n","      \"eos_token_id\": null,\n","      \"exponential_decay_length_penalty\": null,\n","      \"finetuning_task\": null,\n","      \"forced_bos_token_id\": null,\n","      \"forced_eos_token_id\": null,\n","      \"hidden_act\": \"quick_gelu\",\n","      \"hidden_size\": 1024,\n","      \"id2label\": {\n","        \"0\": \"LABEL_0\",\n","        \"1\": \"LABEL_1\"\n","      },\n","      \"image_size\": 448,\n","      \"initializer_factor\": 1.0,\n","      \"initializer_range\": 0.02,\n","      \"intermediate_size\": 4096,\n","      \"is_decoder\": false,\n","      \"is_encoder_decoder\": false,\n","      \"label2id\": {\n","        \"LABEL_0\": 0,\n","        \"LABEL_1\": 1\n","      },\n","      \"layer_norm_eps\": 1e-06,\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 20,\n","      \"min_length\": 0,\n","      \"model_type\": \"mplug_owl_vision_model\",\n","      \"no_repeat_ngram_size\": 0,\n","      \"num_attention_heads\": 16,\n","      \"num_beam_groups\": 1,\n","      \"num_beams\": 1,\n","      \"num_channels\": 3,\n","      \"num_hidden_layers\": 24,\n","      \"num_return_sequences\": 1,\n","      \"output_attentions\": false,\n","      \"output_hidden_states\": false,\n","      \"output_scores\": false,\n","      \"pad_token_id\": null,\n","      \"patch_size\": 14,\n","      \"prefix\": null,\n","      \"problem_type\": null,\n","      \"projection_dim\": 768,\n","      \"pruned_heads\": {},\n","      \"remove_invalid_values\": false,\n","      \"repetition_penalty\": 1.0,\n","      \"return_dict\": true,\n","      \"return_dict_in_generate\": false,\n","      \"sep_token_id\": null,\n","      \"suppress_tokens\": null,\n","      \"task_specific_params\": null,\n","      \"temperature\": 1.0,\n","      \"tf_legacy_loss\": false,\n","      \"tie_encoder_decoder\": false,\n","      \"tie_word_embeddings\": true,\n","      \"tokenizer_class\": null,\n","      \"top_k\": 50,\n","      \"top_p\": 1.0,\n","      \"torch_dtype\": null,\n","      \"torchscript\": false,\n","      \"transformers_version\": \"4.28.1\",\n","      \"typical_p\": 1.0,\n","      \"use_bfloat16\": false,\n","      \"use_flash_attn\": false\n","    }\n","  },\n","  \"vocab_size\": 32000\n","}\n","\n","\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247moptimizer_grouped_parameters\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mparams\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m335\u001b[39m\n","\u001b[38;5;245m    \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247moptimizer_grouped_parameters\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mparams\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m220\u001b[39m\n","False\n","True\n","Formatting inputs...Skip in lazy mode\n","/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n","  warnings.warn(\n","\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247moptimizer_grouped_parameters\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mparams\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m335\u001b[39m\n","\u001b[38;5;245m    \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247moptimizer_grouped_parameters\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mparams\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m220\u001b[39m\n","Parameter Offload: Total persistent parameters: 996352 in 418 params\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanishapanda\u001b[0m (\u001b[33mmanishapanda-texas-a-m-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/Q-Align/wandb/run-20240718_002106-d31zr1u9\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjolly-serenity-5\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/manishapanda-texas-a-m-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/manishapanda-texas-a-m-university/huggingface/runs/d31zr1u9\u001b[0m\n","  0%|                                                     | 0/2 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n","[2024-07-18 00:21:22,284] [WARNING] [stage3.py:1850:step] 6 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n","{'loss': 0.4311, 'learning_rate': 2e-05, 'epoch': 0.4}                          \n"," 50%|██████████████████████▌                      | 1/2 [00:14<00:14, 14.66s/it][2024-07-18 00:21:34,952] [WARNING] [stage3.py:1850:step] 4 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n","{'loss': 0.5396, 'learning_rate': 0.0, 'epoch': 0.8}                            \n","{'train_runtime': 28.9883, 'train_samples_per_second': 0.655, 'train_steps_per_second': 0.069, 'train_loss': 0.4853363037109375, 'epoch': 0.8}\n","100%|█████████████████████████████████████████████| 2/2 [00:27<00:00, 13.74s/it]\n","\u001b[0m/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:557: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n","\n","Thrown during validation:\n","`do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","[2024-07-18 00:21:45,921] [INFO] [launch.py:347:main] Process 8921 exits successfully.\n","\u001b[34m\u001b[1mwandb\u001b[0m: | 0.048 MB of 0.048 MB uploaded\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁██\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁██\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate █▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ▁█\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 0.8\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.5396\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 5493743616.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.48534\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 28.9883\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 0.655\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.069\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mjolly-serenity-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/manishapanda-texas-a-m-university/huggingface/runs/d31zr1u9\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/manishapanda-texas-a-m-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240718_002106-d31zr1u9/logs\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n","\u001b[0m[2024-07-18 00:22:03,944] [INFO] [launch.py:347:main] Process 8920 exits successfully.\n"]}],"source":["!chmod +x scripts/my_videos_lora.sh\n","!bash scripts/my_videos_lora.sh"]},{"cell_type":"code","execution_count":null,"id":"921a7d8f-919f-404f-86b7-90aec9802e8d","metadata":{"id":"921a7d8f-919f-404f-86b7-90aec9802e8d","outputId":"61066e20-e7ee-454a-d3f5-6dc8e33a3b23"},"outputs":[{"name":"stdout","output_type":"stream","text":["config.json\t\t\t  q-align-my-videos-lora\n","pytorch_model-00001-of-00004.bin  special_tokens_map.json\n","pytorch_model-00002-of-00004.bin  tokenizer.model\n","pytorch_model-00003-of-00004.bin  tokenizer_config.json\n","pytorch_model-00004-of-00004.bin  trainer_state.json\n","pytorch_model.bin.index.json\t  training_args.bin\n"]},{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}],"source":["!ls /workspace/Q-Align/checkpoints/"]},{"cell_type":"code","execution_count":null,"id":"176cdff1-9475-4a1f-a6af-74a242498dfa","metadata":{"id":"176cdff1-9475-4a1f-a6af-74a242498dfa","outputId":"67791537-cec2-445d-aeb5-2fb552b6a3c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["/workspace/Q-Align\n"]}],"source":["!pwd\n"]},{"cell_type":"code","execution_count":null,"id":"8f65d083-23ab-4298-a03b-6e2838d6b74d","metadata":{"colab":{"referenced_widgets":["db391d86ec6342debe076a4cd2e03875"]},"id":"8f65d083-23ab-4298-a03b-6e2838d6b74d","outputId":"096e5941-03ad-4a72-a21e-72a3629afb34"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db391d86ec6342debe076a4cd2e03875","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import sys\n","sys.path.append('/workspace/Q-Align')\n","from q_align.evaluate.vqa_eval import main\n","from types import SimpleNamespace\n","\n","args = SimpleNamespace(\n","    model_path=\"/workspace/Q-Align/checkpoints\",\n","    model_base=None,  # Set this to None if loading a full model\n","    device=\"cuda:0\",\n","    conv_mode=None,\n","    temperature=0.2,\n","    max_new_tokens=512,\n","    load_8bit=False,\n","    load_4bit=False,\n","    debug=False,\n","    image_aspect_ratio='pad'\n",")\n","\n","main(args)"]},{"cell_type":"code","execution_count":null,"id":"ad3bec82-c64d-498f-a164-d031ea51f427","metadata":{"id":"ad3bec82-c64d-498f-a164-d031ea51f427","outputId":"e7ad83d0-7da3-48ab-ef93-71af0c94c061"},"outputs":[{"name":"stdout","output_type":"stream","text":["['q-align-my-videos-lora', 'trainer_state.json', 'config.json', 'pytorch_model-00001-of-00004.bin', 'pytorch_model-00002-of-00004.bin', 'pytorch_model-00003-of-00004.bin', 'pytorch_model-00004-of-00004.bin', 'pytorch_model.bin.index.json', 'tokenizer_config.json', 'special_tokens_map.json', 'tokenizer.model', 'training_args.bin', 'preprocessor_config.json']\n"]}],"source":["import os\n","print(os.listdir('/workspace/Q-Align/checkpoints'))\n"]},{"cell_type":"code","execution_count":null,"id":"985e97bb-4e36-483e-a1af-be46c85be9be","metadata":{"id":"985e97bb-4e36-483e-a1af-be46c85be9be"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}