{"cells":[{"cell_type":"code","execution_count":null,"id":"a7ebbf52-fec8-4bf2-afd6-cb7ca734a1b4","metadata":{"id":"a7ebbf52-fec8-4bf2-afd6-cb7ca734a1b4","outputId":"74de679f-401b-4cdd-9dff-840cc7380f0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'Q-Align'...\n","remote: Enumerating objects: 745, done.\u001b[K\n","remote: Counting objects: 100% (13/13), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 745 (delta 3), reused 2 (delta 1), pack-reused 732\u001b[K\n","Receiving objects: 100% (745/745), 42.06 MiB | 19.55 MiB/s, done.\n","Resolving deltas: 100% (440/440), done.\n","Updating files: 100% (177/177), done.\n","/workspace/Q-Align\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n","  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"]},{"name":"stdout","output_type":"stream","text":["Obtaining file:///workspace/Q-Align\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n","\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hCollecting torch==2.0.1\n","  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Collecting torchvision==0.15.2\n","  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n","Collecting transformers==4.36.1\n","  Downloading transformers-4.36.1-py3-none-any.whl.metadata (126 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers==0.15.0\n","  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting sentencepiece==0.1.99\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n","Collecting shortuuid\n","  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n","Collecting accelerate==0.21.0\n","  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n","Collecting peft==0.4.0\n","  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n","Collecting bitsandbytes==0.41.0\n","  Downloading bitsandbytes-0.41.0-py3-none-any.whl.metadata (9.8 kB)\n","Collecting pydantic<2,>=1\n","  Downloading pydantic-1.10.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (151 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting markdown2[all]\n","  Downloading markdown2-2.5.0-py2.py3-none-any.whl.metadata (2.2 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.1)\n","Collecting scikit-learn==1.2.2\n","  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Collecting gradio==3.35.2\n","  Downloading gradio-3.35.2-py3-none-any.whl.metadata (15 kB)\n","Collecting gradio-client==0.2.9\n","  Downloading gradio_client-0.2.9-py3-none-any.whl.metadata (7.0 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Collecting httpx==0.24.0\n","  Downloading httpx-0.24.0-py3-none-any.whl.metadata (8.1 kB)\n","Collecting uvicorn\n","  Downloading uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n","Collecting fastapi\n","  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n","Collecting icecream\n","  Downloading icecream-2.1.3-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting einops==0.6.1\n","  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n","Collecting einops-exts==0.0.4\n","  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n","Collecting timm==0.6.13\n","  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n","Collecting decord\n","  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n","Collecting scipy\n","  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting deepspeed==0.9.5\n","  Downloading deepspeed-0.9.5.tar.gz (809 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.9/809.9 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting ninja\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n","Collecting wandb\n","  Downloading wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (5.9.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (6.0.1)\n","Collecting hjson (from deepspeed==0.9.5)\n","  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting py-cpuinfo (from deepspeed==0.9.5)\n","  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n","Collecting tqdm (from deepspeed==0.9.5)\n","  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles (from gradio==3.35.2)\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Collecting aiohttp (from gradio==3.35.2)\n","  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n","Collecting altair>=4.2.0 (from gradio==3.35.2)\n","  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n","Collecting ffmpy (from gradio==3.35.2)\n","  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio==3.35.2)\n","  Downloading huggingface_hub-0.24.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (3.1.2)\n","Collecting markdown-it-py>=2.0.0 (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2)\n","  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (2.1.2)\n","Collecting matplotlib (from gradio==3.35.2)\n","  Downloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2)\n","  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n","Collecting orjson (from gradio==3.35.2)\n","  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pandas (from gradio==3.35.2)\n","  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (9.3.0)\n","Collecting pydub (from gradio==3.35.2)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2) (2.16.1)\n","Collecting python-multipart (from gradio==3.35.2)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n","Collecting semantic-version (from gradio==3.35.2)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting websockets>=10.0 (from gradio==3.35.2)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.2.9) (2023.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.2.9) (4.4.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0) (2022.12.7)\n","Collecting httpcore<0.18.0,>=0.15.0 (from httpx==0.24.0)\n","  Downloading httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0) (3.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.0) (1.3.0)\n","Collecting safetensors (from peft==0.4.0)\n","  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting joblib>=1.1.1 (from scikit-learn==1.2.2)\n","  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n","Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.2.2)\n","  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.0)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.1)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Collecting regex!=2019.12.17 (from transformers==4.36.1)\n","  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (68.2.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.41.3)\n","Collecting cmake (from triton==2.0.0->torch==2.0.1)\n","  Downloading cmake-3.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.1)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Collecting click>=7.0 (from uvicorn)\n","  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n","Collecting h11>=0.8 (from uvicorn)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Collecting starlette<0.38.0,>=0.37.2 (from fastapi)\n","  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n","Collecting typing-extensions (from gradio-client==0.2.9)\n","  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n","Collecting fastapi-cli>=0.0.2 (from fastapi)\n","  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n","Collecting email_validator>=2.0.0 (from fastapi)\n","  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n","Collecting colorama>=0.3.9 (from icecream)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.0.1)\n","Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.4.1)\n","Collecting wavedrom (from markdown2[all])\n","  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting latex2mathml (from markdown2[all])\n","  Downloading latex2mathml-3.77.0-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (2.1.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.13)\n","Collecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n","Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (3.11.0)\n","Collecting protobuf!=4.21.0,<6,>=3.19.0 (from wandb)\n","  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-2.10.0-py2.py3-none-any.whl.metadata (14 kB)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2) (4.19.2)\n","Collecting toolz (from altair>=4.2.0->gradio==3.35.2)\n","  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n","Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi)\n","  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n","Collecting typer>=0.12.3 (from fastapi-cli>=0.0.2->fastapi)\n","  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0) (4.0.0)\n","Collecting fsspec (from gradio-client==0.2.9)\n","  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n","Collecting mdurl~=0.1 (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2)\n","  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n","Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2)\n","  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n","INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n","Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2)\n","  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n","  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n","  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n","  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl.metadata (2.8 kB)\n","  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl.metadata (2.8 kB)\n","  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n","  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n","INFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n","  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n","  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n","  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n","  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n","  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.35.2)\n","  Downloading markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.35.2) (2.8.2)\n","Collecting pytz>=2020.1 (from pandas->gradio==3.35.2)\n","  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.7 (from pandas->gradio==3.35.2)\n","  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi)\n","  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting aiosignal>=1.1.2 (from aiohttp->gradio==3.35.2)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.35.2) (23.1.0)\n","Collecting frozenlist>=1.1.1 (from aiohttp->gradio==3.35.2)\n","  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->gradio==3.35.2)\n","  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->gradio==3.35.2)\n","  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n","Collecting async-timeout<5.0,>=4.0 (from aiohttp->gradio==3.35.2)\n","  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n","Collecting contourpy>=1.0.1 (from matplotlib->gradio==3.35.2)\n","  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n","Collecting cycler>=0.10 (from matplotlib->gradio==3.35.2)\n","  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n","Collecting fonttools>=4.22.0 (from matplotlib->gradio==3.35.2)\n","  Downloading fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->gradio==3.35.2)\n","  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->gradio==3.35.2) (2.4.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n","Collecting svgwrite (from wavedrom->markdown2[all])\n","  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx==0.24.0) (1.1.3)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2) (0.12.0)\n","Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2)\n","  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n","Collecting shellingham>=1.3.0 (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi)\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n","Collecting rich>=10.11.0 (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi)\n","  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n","Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.41.0-py3-none-any.whl (92.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n","Downloading gradio-3.35.2-py3-none-any.whl (19.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading gradio_client-0.2.9-py3-none-any.whl (288 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.24.0-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading timm-0.6.13-py3-none-any.whl (549 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n","\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading transformers-4.36.1-py3-none-any.whl (8.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading pydantic-1.10.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n","Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n","Downloading wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading altair-5.3.0-py3-none-any.whl (857 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n","Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n","Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.24.1-py3-none-any.whl (417 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.2/417.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading sentry_sdk-2.10.0-py2.py3-none-any.whl (302 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.1/302.1 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n","Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n","Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading markdown2-2.5.0-py2.py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading matplotlib-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n","Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n","Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n","Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n","Checking if build backend supports build_editable ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: deepspeed, q_align, ffmpy, wavedrom\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.9.5-py3-none-any.whl size=844527 sha256=bf2ba3be73c6c77dea4109e4405017926929fcf78c0339d63ea52a96153e63e7\n","  Stored in directory: /root/.cache/pip/wheels/7e/a9/bb/a00d383521da14dc91b65ae2d0062401b750d968a548401b2a\n","  Building editable for q_align (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for q_align: filename=q_align-1.2.0-0.editable-py3-none-any.whl size=7708 sha256=6ac03453cd9bea48c10bf3d6fca6c4f7e064c6b0d74d523f3535e012f3fa4131\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-be026f3i/wheels/6f/99/0b/dd230991014892200c16f9bfed662d47ee4b125637a86ed7ae\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=bc0ce0463895248629ebb6026d7ed0a837d141e146189389a597f77cedf34e59\n","  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n","  Building wheel for wavedrom (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30053 sha256=cab58b12905db0d65cc39f16141061eba21e3fee0d72533fecff4812870c7910\n","  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n","Successfully built deepspeed q_align ffmpy wavedrom\n","Installing collected packages: sentencepiece, pytz, pydub, py-cpuinfo, ninja, lit, hjson, ffmpy, bitsandbytes, websockets, uvloop, uc-micro-py, tzdata, typing-extensions, tqdm, toolz, threadpoolctl, svgwrite, smmap, shortuuid, shellingham, setproctitle, sentry-sdk, semantic-version, scipy, safetensors, regex, python-multipart, python-dotenv, protobuf, orjson, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, multidict, mdurl, markdown2, latex2mathml, kiwisolver, joblib, httptools, h11, fsspec, frozenlist, fonttools, einops, docker-pycreds, dnspython, decord, cycler, contourpy, colorama, cmake, click, async-timeout, aiofiles, yarl, wavedrom, watchfiles, uvicorn, starlette, scikit-learn, pydantic, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, matplotlib, markdown-it-py, linkify-it-py, icecream, huggingface-hub, httpcore, gitdb, email_validator, einops-exts, aiosignal, tokenizers, rich, mdit-py-plugins, httpx, gitpython, aiohttp, wandb, typer, transformers, gradio-client, altair, fastapi-cli, fastapi, gradio, triton, torch, torchvision, accelerate, timm, peft, q_align, deepspeed\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.4.0\n","    Uninstalling typing_extensions-4.4.0:\n","      Successfully uninstalled typing_extensions-4.4.0\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2023.4.0\n","    Uninstalling fsspec-2023.4.0:\n","      Successfully uninstalled fsspec-2023.4.0\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.0+cu118\n","    Uninstalling torch-2.1.0+cu118:\n","      Successfully uninstalled torch-2.1.0+cu118\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.16.0+cu118\n","    Uninstalling torchvision-0.16.0+cu118:\n","      Successfully uninstalled torchvision-0.16.0+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.21.0 aiofiles-24.1.0 aiohttp-3.9.5 aiosignal-1.3.1 altair-5.3.0 async-timeout-4.0.3 bitsandbytes-0.41.0 click-8.1.7 cmake-3.30.1 colorama-0.4.6 contourpy-1.2.1 cycler-0.12.1 decord-0.6.0 deepspeed-0.9.5 dnspython-2.6.1 docker-pycreds-0.4.0 einops-0.6.1 einops-exts-0.0.4 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 ffmpy-0.3.2 fonttools-4.53.1 frozenlist-1.4.1 fsspec-2024.6.1 gitdb-4.0.11 gitpython-3.1.43 gradio-3.35.2 gradio-client-0.2.9 h11-0.14.0 hjson-3.1.0 httpcore-0.17.3 httptools-0.6.1 httpx-0.24.0 huggingface-hub-0.24.1 icecream-2.1.3 joblib-1.4.2 kiwisolver-1.4.5 latex2mathml-3.77.0 linkify-it-py-2.0.3 lit-18.1.8 markdown-it-py-2.2.0 markdown2-2.5.0 matplotlib-3.9.1 mdit-py-plugins-0.3.3 mdurl-0.1.2 multidict-6.0.5 ninja-1.11.1.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 orjson-3.10.6 pandas-2.2.2 peft-0.4.0 protobuf-5.27.2 py-cpuinfo-9.0.0 pydantic-1.10.17 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 pytz-2024.1 q_align-1.2.0 regex-2024.5.15 rich-13.7.1 safetensors-0.4.3 scikit-learn-1.2.2 scipy-1.14.0 semantic-version-2.10.0 sentencepiece-0.1.99 sentry-sdk-2.10.0 setproctitle-1.3.3 shellingham-1.5.4 shortuuid-1.0.13 smmap-5.0.1 starlette-0.37.2 svgwrite-1.4.3 threadpoolctl-3.5.0 timm-0.6.13 tokenizers-0.15.0 toolz-0.12.1 torch-2.0.1 torchvision-0.15.2 tqdm-4.66.4 transformers-4.36.1 triton-2.0.0 typer-0.12.3 typing-extensions-4.12.2 tzdata-2024.1 uc-micro-py-1.0.3 uvicorn-0.30.3 uvloop-0.19.0 wandb-0.17.5 watchfiles-0.22.0 wavedrom-2.0.3.post3 websockets-12.0 yarl-1.9.4\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n","Collecting flash_attn\n","  Downloading flash_attn-2.6.2.tar.gz (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash_attn) (2.0.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash_attn) (0.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.9.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash_attn) (68.2.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash_attn) (0.41.3)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash_attn) (3.30.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash_attn) (18.1.8)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash_attn) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash_attn) (1.3.0)\n","Building wheels for collected packages: flash_attn\n","  Building wheel for flash_attn (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for flash_attn: filename=flash_attn-2.6.2-cp310-cp310-linux_x86_64.whl size=188930444 sha256=4d2d7f9a992c9fb781beab571caabd7602ad25c5f52ccfb8f5c6740eeb203c61\n","  Stored in directory: /root/.cache/pip/wheels/a8/20/ee/e5b01112422114bf788fea51bb25589e7134aad5f38b1a9b09\n","Successfully built flash_attn\n","Installing collected packages: flash_attn\n","Successfully installed flash_attn-2.6.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"]}],"source":["!git clone https://github.com/Q-Future/Q-Align.git\n","%cd Q-Align\n","!pip install -e \".[train]\"\n","!pip install flash_attn --no-build-isolation"]},{"cell_type":"code","execution_count":null,"id":"11d21e5a-3e9e-43ec-a8f0-ebb676c986dc","metadata":{"id":"11d21e5a-3e9e-43ec-a8f0-ebb676c986dc","outputId":"302b6dc4-e97d-4723-b189-9f73097c08f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: deepspeed in /usr/local/lib/python3.10/dist-packages (0.9.5)\n","Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed) (3.1.0)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.11.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.24.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.6)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n","Requirement already satisfied: pydantic<2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.10.17)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->deepspeed) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deepspeed) (68.2.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deepspeed) (0.41.3)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (3.30.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (18.1.8)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install deepspeed"]},{"cell_type":"code","execution_count":null,"id":"69e2a704-d3f6-475c-964f-862c2c2cb2cd","metadata":{"id":"69e2a704-d3f6-475c-964f-862c2c2cb2cd"},"outputs":[],"source":["# Copy JSON file\n","!cp /workspace/train_split_1.json /workspace/Q-Align/playground/data/ft/\n","\n","# Create directory for video data\n","!mkdir -p /workspace/video_data\n","\n","# Copy video files\n","!cp /workspace/*.mp4 /workspace/video_data/\n","# If you have GIF files, use this command as well:\n","# !cp /content/drive/MyDrive/Q-Align_data/*.gif /content/video_data/"]},{"cell_type":"code","execution_count":null,"id":"cd04952c-ecd8-48a0-bbe3-c97002cfe911","metadata":{"id":"cd04952c-ecd8-48a0-bbe3-c97002cfe911","outputId":"cd861b0e-ef32-4480-dc79-2283ba80bba6"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 13689\n","drwxrwxrwx 2 root root 2000678 Jul 24 00:18 agi\n","drwxrwxrwx 2 root root 2000106 Jul 24 00:18 agiqa3k\n","drwxrwxrwx 2 root root 2001283 Jul 24 00:18 cgi\n","drwxrwxrwx 2 root root 2000169 Jul 24 00:18 csiq\n","drwxrwxrwx 2 root root 2000211 Jul 24 00:18 live\n","drwxrwxrwx 2 root root 2000250 Jul 24 00:18 livec\n","drwxrwxrwx 2 root root 2000105 Jul 24 00:18 maxwell\n","-rw-rw-rw- 1 root root   13077 Jul 24 00:31 train_split_1.json\n","total 39856\n","-rw-rw-rw- 1 root root 1367318 Jul 24 00:31  Anatomy_Bad.mp4\n","-rw-rw-rw- 1 root root 1730556 Jul 24 00:31  Beach_Good.mp4\n","-rw-rw-rw- 1 root root  710597 Jul 24 00:31  BeachwithProduct_Good.mp4\n","-rw-rw-rw- 1 root root 2548897 Jul 24 00:31  Building_Bad.mp4\n","-rw-rw-rw- 1 root root 1551262 Jul 24 00:31  Building_Color_Bad.mp4\n","-rw-rw-rw- 1 root root 1555896 Jul 24 00:31  Building_Color_worse.mp4\n","-rw-rw-rw- 1 root root 4063180 Jul 24 00:31  Building_Very_Bad.mp4\n","-rw-rw-rw- 1 root root  826721 Jul 24 00:31  ExtraHand_Bad.mp4\n","-rw-rw-rw- 1 root root  238587 Jul 24 00:31  FLowers_anatomy.mp4\n","-rw-rw-rw- 1 root root  596551 Jul 24 00:31  Girl_eye_more_bad.mp4\n","-rw-rw-rw- 1 root root  342580 Jul 24 00:31  Girl_eyes_bad.mp4\n","-rw-rw-rw- 1 root root 1825339 Jul 24 00:31  Gym_Bad.mp4\n","-rw-rw-rw- 1 root root  516416 Jul 24 00:31  HeadAndShoulder_Good.mp4\n","-rw-rw-rw- 1 root root  930190 Jul 24 00:31  Human_Moving_Backward.mp4\n","-rw-rw-rw- 1 root root 1101616 Jul 24 00:31  Light1_Bad.mp4\n","-rw-rw-rw- 1 root root  958046 Jul 24 00:31  Mask_good.mp4\n","-rw-rw-rw- 1 root root  627003 Jul 24 00:31  Plum_Good.mp4\n","-rw-rw-rw- 1 root root 1101616 Jul 24 00:31  ShampooBottle_Bad.mp4\n","-rw-rw-rw- 1 root root  717811 Jul 24 00:31  Smile_Good.mp4\n","-rw-rw-rw- 1 root root  838754 Jul 24 00:31  SmillingFace_Good.mp4\n","-rw-rw-rw- 1 root root  146131 Jul 24 00:31  SpiderMan_Bad.mp4\n","-rw-rw-rw- 1 root root  665636 Jul 24 00:31  Sunrise_Good.mp4\n","-rw-rw-rw- 1 root root 1439541 Jul 24 00:31  Temporal_Bad.mp4\n","-rw-rw-rw- 1 root root 1048281 Jul 24 00:31  Water_Good.mp4\n","-rw-rw-rw- 1 root root 1226843 Jul 24 00:31  Waterfalling_Decent.mp4\n","-rw-rw-rw- 1 root root 1154239 Jul 24 00:31  WomanEyeDistortion_Bad.mp4\n","-rw-rw-rw- 1 root root 1410517 Jul 24 00:31  WomanShampoo_Decent.mp4\n","-rw-rw-rw- 1 root root  710597 Jul 24 00:31  WomenwithProduct_Good.mp4\n","-rw-rw-rw- 1 root root 1825339 Jul 24 00:31  WorkingOut_Bad.mp4\n","-rw-rw-rw- 1 root root 1151986 Jul 24 00:31  colorcode_bad.mp4\n","-rw-rw-rw- 1 root root  313332 Jul 24 00:31 'i2v (17).mp4'\n","-rw-rw-rw- 1 root root  414470 Jul 24 00:31 'i2v (20).mp4'\n","-rw-rw-rw- 1 root root  394233 Jul 24 00:31 'i2v (8).mp4'\n","-rw-rw-rw- 1 root root  715245 Jul 24 00:31  i2v.mp4\n","-rw-rw-rw- 1 root root  926607 Jul 24 00:31  light_bad.mp4\n","-rw-rw-rw- 1 root root 1033072 Jul 24 00:31  water_bad.mp4\n","-rw-rw-rw- 1 root root  944233 Jul 24 00:31  water_girl_bad.mp4\n","-rw-rw-rw- 1 root root 1135137 Jul 24 00:31  women_Very_bad.mp4\n"]}],"source":["!ls -l /workspace/Q-Align/playground/data/ft/\n","!ls -l /workspace/video_data/"]},{"cell_type":"code","execution_count":null,"id":"615a619b-31d3-4c33-aa38-55196cde03b1","metadata":{"id":"615a619b-31d3-4c33-aa38-55196cde03b1","outputId":"b9e2dade-3ebd-4090-90f7-9a6e83e3cad1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing scripts/my_videos_lora.sh\n"]}],"source":["%%writefile scripts/my_videos_lora.sh\n","#!/bin/bash\n","\n","# Create input file with choice\n","echo \"2\" > input.txt\n","export WANDB_API_KEY=\"d748b17184ce7ec9c05419bb670fbda0fd136a13\"\n","\n","wandb login $WANDB_API_KEY\n","\n","# Run the script with input redirection\n","deepspeed q_align/train/train_mem.py < input.txt \\\n","    --deepspeed ./scripts/zero3.json \\\n","    --model_name_or_path q-future/one-align \\\n","    --version v1 \\\n","    --data_path /workspace/Q-Align/playground/data/ft/train_split_1.json \\\n","    --image_folder /workspace/video_data \\\n","    --bf16 True \\\n","    --output_dir /workspace/Q-Align/checkpoints/ \\\n","    --num_train_epochs 1 \\\n","    --per_device_train_batch_size 1 \\\n","    --per_device_eval_batch_size 1 \\\n","    --gradient_accumulation_step 4 \\\n","    --evaluation_strategy \"no\" \\\n","    --save_strategy \"steps\" \\\n","    --save_steps 50000 \\\n","    --save_total_limit 1 \\\n","    --learning_rate 2e-5 \\\n","    --weight_decay 0. \\\n","    --warmup_ratio 0.03 \\\n","    --lr_scheduler_type \"cosine\" \\\n","    --logging_steps 1 \\\n","    --tf32 True \\\n","    --model_max_length 2048 \\\n","    --gradient_checkpointing True \\\n","    --dataloader_num_workers 4 \\\n","    --lazy_preprocess True \\\n","    --report_to wandb\n"]},{"cell_type":"markdown","id":"fe7c991d-00a0-47ee-82a2-b3f33defd81e","metadata":{"id":"fe7c991d-00a0-47ee-82a2-b3f33defd81e"},"source":[]},{"cell_type":"code","execution_count":null,"id":"92e3c21d-2df6-4623-ac92-d9f2ad54df67","metadata":{"id":"92e3c21d-2df6-4623-ac92-d9f2ad54df67","outputId":"033709fc-6ed7-44f5-8c76-d4edb40a8f30"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","[2024-07-24 00:31:24,117] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-07-24 00:31:26,243] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n","[2024-07-24 00:31:26,243] [INFO] [runner.py:555:main] cmd = /usr/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None q_align/train/train_mem.py --deepspeed ./scripts/zero3.json --model_name_or_path q-future/one-align --version v1 --data_path /workspace/Q-Align/playground/data/ft/train_split_1.json --image_folder /workspace/video_data --bf16 True --output_dir /workspace/Q-Align/checkpoints/ --num_train_epochs 1 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_step 4 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb\n","[2024-07-24 00:31:27,648] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.15.5-1+cuda11.8\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.15.5-1\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.15.5-1\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.15.5-1+cuda11.8\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.15.5-1\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1]}\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:163:main] dist_world_size=2\n","[2024-07-24 00:31:29,764] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1\n","[2024-07-24 00:31:32,909] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-07-24 00:31:33,006] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-07-24 00:31:33,713] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n","[2024-07-24 00:31:33,713] [INFO] [comm.py:594:init_distributed] cdb=None\n","[2024-07-24 00:31:33,713] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n","[2024-07-24 00:31:33,741] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n","[2024-07-24 00:31:33,741] [INFO] [comm.py:594:init_distributed] cdb=None\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n","Instantiating LlamaAttention without passing `layer_idx` is not recommended and will to errors during the forward call, if caching is used. Please make sure to provide a `layer_idx` when creating this class.\n","Instantiating LlamaAttention without passing `layer_idx` is not recommended and will to errors during the forward call, if caching is used. Please make sure to provide a `layer_idx` when creating this class.\n","[2024-07-24 00:31:37,948] [WARNING] [partition_parameters.py:836:_post_init_method] param `cls_token` in MplugOwlVisionEmbeddings not on GPU so was not broadcasted from rank 0\n","[2024-07-24 00:31:37,948] [WARNING] [partition_parameters.py:836:_post_init_method] param `position_embedding` in MplugOwlVisionEmbeddings not on GPU so was not broadcasted from rank 0\n","[2024-07-24 00:31:38,229] [WARNING] [partition_parameters.py:836:_post_init_method] param `query_embeds` in MplugOwlVisualAbstractorModel not on GPU so was not broadcasted from rank 0\n","[2024-07-24 00:31:38,236] [WARNING] [partition_parameters.py:836:_post_init_method] param `vit_eos` in MplugOwlVisualAbstractorModel not on GPU so was not broadcasted from rank 0\n","[2024-07-24 00:31:38,716] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 11.42B parameters\n","Loading checkpoint shards: 100%|██████████████████| 2/2 [00:17<00:00,  8.76s/it]\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","MPLUGOwl2Config {\n","  \"_name_or_path\": \"q-future/one-align\",\n","  \"architectures\": [\n","    \"MPLUGOwl2LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"q-future/one-align--configuration_mplug_owl2.MPLUGOwl2Config\",\n","    \"AutoModel\": \"q-future/one-align--modeling_mplug_owl2.MPLUGOwl2LlamaForCausalLM\",\n","    \"AutoModelForCausalLM\": \"q-future/one-align--modeling_mplug_owl2.MPLUGOwl2LlamaForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2,\n","  \"freeze_vision_model\": false,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 4096,\n","  \"image_aspect_ratio\": \"pad\",\n","  \"image_grid_pinpoints\": null,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 11008,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"mplug_owl2\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.36.1\",\n","  \"tune_visual_abstractor\": true,\n","  \"use_cache\": true,\n","  \"visual_abstractor_lr\": null,\n","  \"visual_config\": {\n","    \"visual_abstractor\": {\n","      \"_name_or_path\": \"\",\n","      \"add_cross_attention\": false,\n","      \"architectures\": null,\n","      \"attention_probs_dropout_prob\": 0.0,\n","      \"bad_words_ids\": null,\n","      \"begin_suppress_tokens\": null,\n","      \"bos_token_id\": null,\n","      \"chunk_size_feed_forward\": 0,\n","      \"cross_attention_hidden_size\": null,\n","      \"decoder_start_token_id\": null,\n","      \"diversity_penalty\": 0.0,\n","      \"do_sample\": false,\n","      \"early_stopping\": false,\n","      \"encoder_hidden_size\": 1024,\n","      \"encoder_no_repeat_ngram_size\": 0,\n","      \"eos_token_id\": null,\n","      \"exponential_decay_length_penalty\": null,\n","      \"finetuning_task\": null,\n","      \"forced_bos_token_id\": null,\n","      \"forced_eos_token_id\": null,\n","      \"grid_size\": 32,\n","      \"hidden_size\": 1024,\n","      \"id2label\": {\n","        \"0\": \"LABEL_0\",\n","        \"1\": \"LABEL_1\"\n","      },\n","      \"initializer_range\": 0.02,\n","      \"intermediate_size\": 2816,\n","      \"is_decoder\": false,\n","      \"is_encoder_decoder\": false,\n","      \"label2id\": {\n","        \"LABEL_0\": 0,\n","        \"LABEL_1\": 1\n","      },\n","      \"layer_norm_eps\": 1e-06,\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 20,\n","      \"min_length\": 0,\n","      \"model_type\": \"mplug_owl_visual_abstract\",\n","      \"no_repeat_ngram_size\": 0,\n","      \"num_attention_heads\": 16,\n","      \"num_beam_groups\": 1,\n","      \"num_beams\": 1,\n","      \"num_hidden_layers\": 6,\n","      \"num_learnable_queries\": 64,\n","      \"num_return_sequences\": 1,\n","      \"output_attentions\": false,\n","      \"output_hidden_states\": false,\n","      \"output_scores\": false,\n","      \"pad_token_id\": null,\n","      \"prefix\": null,\n","      \"problem_type\": null,\n","      \"pruned_heads\": {},\n","      \"remove_invalid_values\": false,\n","      \"repetition_penalty\": 1.0,\n","      \"return_dict\": true,\n","      \"return_dict_in_generate\": false,\n","      \"sep_token_id\": null,\n","      \"suppress_tokens\": null,\n","      \"task_specific_params\": null,\n","      \"temperature\": 1.0,\n","      \"tf_legacy_loss\": false,\n","      \"tie_encoder_decoder\": false,\n","      \"tie_word_embeddings\": true,\n","      \"tokenizer_class\": null,\n","      \"top_k\": 50,\n","      \"top_p\": 1.0,\n","      \"torch_dtype\": null,\n","      \"torchscript\": false,\n","      \"transformers_version\": \"4.28.1\",\n","      \"typical_p\": 1.0,\n","      \"use_bfloat16\": false\n","    },\n","    \"visual_model\": {\n","      \"_name_or_path\": \"\",\n","      \"add_cross_attention\": false,\n","      \"architectures\": null,\n","      \"attention_dropout\": 0.0,\n","      \"bad_words_ids\": null,\n","      \"begin_suppress_tokens\": null,\n","      \"bos_token_id\": null,\n","      \"chunk_size_feed_forward\": 0,\n","      \"cross_attention_hidden_size\": null,\n","      \"decoder_start_token_id\": null,\n","      \"diversity_penalty\": 0.0,\n","      \"do_sample\": false,\n","      \"early_stopping\": false,\n","      \"encoder_no_repeat_ngram_size\": 0,\n","      \"eos_token_id\": null,\n","      \"exponential_decay_length_penalty\": null,\n","      \"finetuning_task\": null,\n","      \"forced_bos_token_id\": null,\n","      \"forced_eos_token_id\": null,\n","      \"hidden_act\": \"quick_gelu\",\n","      \"hidden_size\": 1024,\n","      \"id2label\": {\n","        \"0\": \"LABEL_0\",\n","        \"1\": \"LABEL_1\"\n","      },\n","      \"image_size\": 448,\n","      \"initializer_factor\": 1.0,\n","      \"initializer_range\": 0.02,\n","      \"intermediate_size\": 4096,\n","      \"is_decoder\": false,\n","      \"is_encoder_decoder\": false,\n","      \"label2id\": {\n","        \"LABEL_0\": 0,\n","        \"LABEL_1\": 1\n","      },\n","      \"layer_norm_eps\": 1e-06,\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 20,\n","      \"min_length\": 0,\n","      \"model_type\": \"mplug_owl_vision_model\",\n","      \"no_repeat_ngram_size\": 0,\n","      \"num_attention_heads\": 16,\n","      \"num_beam_groups\": 1,\n","      \"num_beams\": 1,\n","      \"num_channels\": 3,\n","      \"num_hidden_layers\": 24,\n","      \"num_return_sequences\": 1,\n","      \"output_attentions\": false,\n","      \"output_hidden_states\": false,\n","      \"output_scores\": false,\n","      \"pad_token_id\": null,\n","      \"patch_size\": 14,\n","      \"prefix\": null,\n","      \"problem_type\": null,\n","      \"projection_dim\": 768,\n","      \"pruned_heads\": {},\n","      \"remove_invalid_values\": false,\n","      \"repetition_penalty\": 1.0,\n","      \"return_dict\": true,\n","      \"return_dict_in_generate\": false,\n","      \"sep_token_id\": null,\n","      \"suppress_tokens\": null,\n","      \"task_specific_params\": null,\n","      \"temperature\": 1.0,\n","      \"tf_legacy_loss\": false,\n","      \"tie_encoder_decoder\": false,\n","      \"tie_word_embeddings\": true,\n","      \"tokenizer_class\": null,\n","      \"top_k\": 50,\n","      \"top_p\": 1.0,\n","      \"torch_dtype\": null,\n","      \"torchscript\": false,\n","      \"transformers_version\": \"4.28.1\",\n","      \"typical_p\": 1.0,\n","      \"use_bfloat16\": false,\n","      \"use_flash_attn\": false\n","    }\n","  },\n","  \"vocab_size\": 32000\n","}\n","\n","False\n","True\n","/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n","  warnings.warn(\n","Loading checkpoint shards: 100%|██████████████████| 2/2 [00:17<00:00,  8.99s/it]\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","MPLUGOwl2Config {\n","  \"_name_or_path\": \"q-future/one-align\",\n","  \"architectures\": [\n","    \"MPLUGOwl2LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"q-future/one-align--configuration_mplug_owl2.MPLUGOwl2Config\",\n","    \"AutoModel\": \"q-future/one-align--modeling_mplug_owl2.MPLUGOwl2LlamaForCausalLM\",\n","    \"AutoModelForCausalLM\": \"q-future/one-align--modeling_mplug_owl2.MPLUGOwl2LlamaForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2,\n","  \"freeze_vision_model\": false,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 4096,\n","  \"image_aspect_ratio\": \"pad\",\n","  \"image_grid_pinpoints\": null,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 11008,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"mplug_owl2\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.36.1\",\n","  \"tune_visual_abstractor\": true,\n","  \"use_cache\": true,\n","  \"visual_abstractor_lr\": null,\n","  \"visual_config\": {\n","    \"visual_abstractor\": {\n","      \"_name_or_path\": \"\",\n","      \"add_cross_attention\": false,\n","      \"architectures\": null,\n","      \"attention_probs_dropout_prob\": 0.0,\n","      \"bad_words_ids\": null,\n","      \"begin_suppress_tokens\": null,\n","      \"bos_token_id\": null,\n","      \"chunk_size_feed_forward\": 0,\n","      \"cross_attention_hidden_size\": null,\n","      \"decoder_start_token_id\": null,\n","      \"diversity_penalty\": 0.0,\n","      \"do_sample\": false,\n","      \"early_stopping\": false,\n","      \"encoder_hidden_size\": 1024,\n","      \"encoder_no_repeat_ngram_size\": 0,\n","      \"eos_token_id\": null,\n","      \"exponential_decay_length_penalty\": null,\n","      \"finetuning_task\": null,\n","      \"forced_bos_token_id\": null,\n","      \"forced_eos_token_id\": null,\n","      \"grid_size\": 32,\n","      \"hidden_size\": 1024,\n","      \"id2label\": {\n","        \"0\": \"LABEL_0\",\n","        \"1\": \"LABEL_1\"\n","      },\n","      \"initializer_range\": 0.02,\n","      \"intermediate_size\": 2816,\n","      \"is_decoder\": false,\n","      \"is_encoder_decoder\": false,\n","      \"label2id\": {\n","        \"LABEL_0\": 0,\n","        \"LABEL_1\": 1\n","      },\n","      \"layer_norm_eps\": 1e-06,\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 20,\n","      \"min_length\": 0,\n","      \"model_type\": \"mplug_owl_visual_abstract\",\n","      \"no_repeat_ngram_size\": 0,\n","      \"num_attention_heads\": 16,\n","      \"num_beam_groups\": 1,\n","      \"num_beams\": 1,\n","      \"num_hidden_layers\": 6,\n","      \"num_learnable_queries\": 64,\n","      \"num_return_sequences\": 1,\n","      \"output_attentions\": false,\n","      \"output_hidden_states\": false,\n","      \"output_scores\": false,\n","      \"pad_token_id\": null,\n","      \"prefix\": null,\n","      \"problem_type\": null,\n","      \"pruned_heads\": {},\n","      \"remove_invalid_values\": false,\n","      \"repetition_penalty\": 1.0,\n","      \"return_dict\": true,\n","      \"return_dict_in_generate\": false,\n","      \"sep_token_id\": null,\n","      \"suppress_tokens\": null,\n","      \"task_specific_params\": null,\n","      \"temperature\": 1.0,\n","      \"tf_legacy_loss\": false,\n","      \"tie_encoder_decoder\": false,\n","      \"tie_word_embeddings\": true,\n","      \"tokenizer_class\": null,\n","      \"top_k\": 50,\n","      \"top_p\": 1.0,\n","      \"torch_dtype\": null,\n","      \"torchscript\": false,\n","      \"transformers_version\": \"4.28.1\",\n","      \"typical_p\": 1.0,\n","      \"use_bfloat16\": false\n","    },\n","    \"visual_model\": {\n","      \"_name_or_path\": \"\",\n","      \"add_cross_attention\": false,\n","      \"architectures\": null,\n","      \"attention_dropout\": 0.0,\n","      \"bad_words_ids\": null,\n","      \"begin_suppress_tokens\": null,\n","      \"bos_token_id\": null,\n","      \"chunk_size_feed_forward\": 0,\n","      \"cross_attention_hidden_size\": null,\n","      \"decoder_start_token_id\": null,\n","      \"diversity_penalty\": 0.0,\n","      \"do_sample\": false,\n","      \"early_stopping\": false,\n","      \"encoder_no_repeat_ngram_size\": 0,\n","      \"eos_token_id\": null,\n","      \"exponential_decay_length_penalty\": null,\n","      \"finetuning_task\": null,\n","      \"forced_bos_token_id\": null,\n","      \"forced_eos_token_id\": null,\n","      \"hidden_act\": \"quick_gelu\",\n","      \"hidden_size\": 1024,\n","      \"id2label\": {\n","        \"0\": \"LABEL_0\",\n","        \"1\": \"LABEL_1\"\n","      },\n","      \"image_size\": 448,\n","      \"initializer_factor\": 1.0,\n","      \"initializer_range\": 0.02,\n","      \"intermediate_size\": 4096,\n","      \"is_decoder\": false,\n","      \"is_encoder_decoder\": false,\n","      \"label2id\": {\n","        \"LABEL_0\": 0,\n","        \"LABEL_1\": 1\n","      },\n","      \"layer_norm_eps\": 1e-06,\n","      \"length_penalty\": 1.0,\n","      \"max_length\": 20,\n","      \"min_length\": 0,\n","      \"model_type\": \"mplug_owl_vision_model\",\n","      \"no_repeat_ngram_size\": 0,\n","      \"num_attention_heads\": 16,\n","      \"num_beam_groups\": 1,\n","      \"num_beams\": 1,\n","      \"num_channels\": 3,\n","      \"num_hidden_layers\": 24,\n","      \"num_return_sequences\": 1,\n","      \"output_attentions\": false,\n","      \"output_hidden_states\": false,\n","      \"output_scores\": false,\n","      \"pad_token_id\": null,\n","      \"patch_size\": 14,\n","      \"prefix\": null,\n","      \"problem_type\": null,\n","      \"projection_dim\": 768,\n","      \"pruned_heads\": {},\n","      \"remove_invalid_values\": false,\n","      \"repetition_penalty\": 1.0,\n","      \"return_dict\": true,\n","      \"return_dict_in_generate\": false,\n","      \"sep_token_id\": null,\n","      \"suppress_tokens\": null,\n","      \"task_specific_params\": null,\n","      \"temperature\": 1.0,\n","      \"tf_legacy_loss\": false,\n","      \"tie_encoder_decoder\": false,\n","      \"tie_word_embeddings\": true,\n","      \"tokenizer_class\": null,\n","      \"top_k\": 50,\n","      \"top_p\": 1.0,\n","      \"torch_dtype\": null,\n","      \"torchscript\": false,\n","      \"transformers_version\": \"4.28.1\",\n","      \"typical_p\": 1.0,\n","      \"use_bfloat16\": false,\n","      \"use_flash_attn\": false\n","    }\n","  },\n","  \"vocab_size\": 32000\n","}\n","\n","False\n","True\n","Formatting inputs...Skip in lazy mode\n","/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n","  warnings.warn(\n","\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247moptimizer_grouped_parameters\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mparams\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m335\u001b[39m\n","\u001b[38;5;245m    \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247moptimizer_grouped_parameters\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mparams\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m220\u001b[39m\n","\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247moptimizer_grouped_parameters\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m0\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mparams\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m335\u001b[39m\n","\u001b[38;5;245m    \u001b[39m\u001b[38;5;32mlen\u001b[39m\u001b[38;5;245m(\u001b[39m\u001b[38;5;247moptimizer_grouped_parameters\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m[\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mparams\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m]\u001b[39m\u001b[38;5;245m)\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m220\u001b[39m\n","Parameter Offload: Total persistent parameters: 996352 in 418 params\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanishapanda\u001b[0m (\u001b[33mmanishapanda-texas-a-m-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/Q-Align/wandb/run-20240724_003210-96hffl8b\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrich-snowflake-7\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/manishapanda-texas-a-m-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/manishapanda-texas-a-m-university/huggingface/runs/96hffl8b\u001b[0m\n","  0%|                                                     | 0/3 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n","[00:32:25] /github/workspace/src/video/video_reader.cc:83: ERROR opening: /workspace/video_data/EyesDistorted_Bad.mp4, No such file or directory\n","Error reading /workspace/video_data/EyesDistorted_Bad.mp4...\n","[2024-07-24 00:32:30,682] [WARNING] [stage3.py:1850:step] 7 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n","{'loss': 0.3595, 'learning_rate': 2e-05, 'epoch': 0.29}                         \n"," 33%|███████████████                              | 1/3 [00:19<00:38, 19.28s/it][2024-07-24 00:32:47,182] [WARNING] [stage3.py:1850:step] 5 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n","{'loss': 0.4942, 'learning_rate': 1e-05, 'epoch': 0.57}                         \n"," 67%|██████████████████████████████               | 2/3 [00:35<00:17, 17.65s/it][2024-07-24 00:33:03,608] [WARNING] [stage3.py:1850:step] 5 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n","{'loss': 0.0992, 'learning_rate': 0.0, 'epoch': 0.86}                           \n","{'train_runtime': 54.5197, 'train_samples_per_second': 0.514, 'train_steps_per_second': 0.055, 'train_loss': 0.3176066080729167, 'epoch': 0.86}\n","100%|█████████████████████████████████████████████| 3/3 [00:52<00:00, 17.44s/it]\n","\u001b[0m/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:557: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n","\n","Thrown during validation:\n","`do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","[2024-07-24 00:33:19,887] [INFO] [launch.py:347:main] Process 3737 exits successfully.\n","\u001b[34m\u001b[1mwandb\u001b[0m: | 0.034 MB of 0.034 MB uploaded\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▄██\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▅██\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate █▅▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ▆█▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 0.86\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 3\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.0992\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 8605163520.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.31761\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 54.5197\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 0.514\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.055\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrich-snowflake-7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/manishapanda-texas-a-m-university/huggingface/runs/96hffl8b\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/manishapanda-texas-a-m-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240724_003210-96hffl8b/logs\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n","\u001b[0m[2024-07-24 00:34:08,936] [INFO] [launch.py:347:main] Process 3736 exits successfully.\n"]}],"source":["!chmod +x scripts/my_videos_lora.sh\n","!bash scripts/my_videos_lora.sh"]},{"cell_type":"code","execution_count":null,"id":"b79667fe-ee4e-428f-882e-203d0b495e17","metadata":{"id":"b79667fe-ee4e-428f-882e-203d0b495e17","outputId":"9094f66a-52cd-4d53-c52c-1c1d67c57106"},"outputs":[{"name":"stdout","output_type":"stream","text":["File copied from preprocessor_config.json to /workspace/Q-Align/checkpoints/preprocessor_config.json\n"]}],"source":["import shutil\n","import os\n","\n","source_path = \"preprocessor_config.json\"\n","destination_path = \"/workspace/Q-Align/checkpoints/preprocessor_config.json\"\n","\n","# Ensure the destination directory exists\n","os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n","\n","# Copy the file\n","shutil.copy2(source_path, destination_path)\n","\n","print(f\"File copied from {source_path} to {destination_path}\")"]},{"cell_type":"code","execution_count":null,"id":"921a7d8f-919f-404f-86b7-90aec9802e8d","metadata":{"id":"921a7d8f-919f-404f-86b7-90aec9802e8d","outputId":"0346d26d-673e-4383-c320-63e0779ff02a"},"outputs":[{"name":"stdout","output_type":"stream","text":["config.json\t\t\t  pytorch_model.bin.index.json\n","preprocessor_config.json\t  special_tokens_map.json\n","pytorch_model-00001-of-00004.bin  tokenizer.model\n","pytorch_model-00002-of-00004.bin  tokenizer_config.json\n","pytorch_model-00003-of-00004.bin  trainer_state.json\n","pytorch_model-00004-of-00004.bin  training_args.bin\n"]}],"source":["!ls /workspace/Q-Align/checkpoints/"]},{"cell_type":"code","execution_count":null,"id":"176cdff1-9475-4a1f-a6af-74a242498dfa","metadata":{"id":"176cdff1-9475-4a1f-a6af-74a242498dfa","outputId":"8e927d6e-f652-4a8d-c87b-79510ed363c2"},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["/workspace/Q-Align\n"]}],"source":["!pwd\n"]},{"cell_type":"code","execution_count":null,"id":"8f65d083-23ab-4298-a03b-6e2838d6b74d","metadata":{"id":"8f65d083-23ab-4298-a03b-6e2838d6b74d","outputId":"fda74a2e-78a1-4d0b-86af-c2cdf01e93a6","colab":{"referenced_widgets":["35c66f8adcc340c9a6cbcf68c157a29e"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35c66f8adcc340c9a6cbcf68c157a29e","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['good', 'poor', 'high', 'fair', 'low', 'excellent', 'bad', 'fine', 'moderate', 'decent', 'average', 'medium', 'acceptable']\n","[1781, 6460, 1880, 6534, 4482, 15129, 4319, 2691, 17768, 27189, 6588, 18350, 22691]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating [test_custom_videos.json]: 100%|██████████| 4/4 [00:00<00:00,  4.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Spearmanr 0.7745966692414834 Pearson 0.6473548215720712\n"]}],"source":["import sys\n","sys.path.append('/workspace/Q-Align')\n","from q_align.evaluate.vqa_eval import main\n","from types import SimpleNamespace\n","\n","args = SimpleNamespace(\n","    model_path=\"/workspace/Q-Align/checkpoints\",\n","    model_base=None,  # Set this to None if loading a full model\n","    device=\"cuda:0\",\n","    conv_mode=None,\n","    temperature=0.2,\n","    max_new_tokens=512,\n","    load_8bit=False,\n","    load_4bit=False,\n","    debug=False,\n","    image_aspect_ratio='pad'\n",")\n","\n","main(args)\n","\n","# [\n","# {\n","#     \"img_path\": \"i2v.mp4\",\n","#     \"gt_score\": 3\n","#   },\n","#   {\n","#     \"img_path\": \"i2v (17).mp4\",\n","#     \"gt_score\": 1\n","#   },\n","#   {\n","#     \"img_path\": \"i2v (20).mp4\",\n","#     \"gt_score\": 1\n","#   },\n","#   {\n","#     \"img_path\": \"i2v (8).mp4\",\n","#     \"gt_score\": 1\n","#   }\n","# ]"]},{"cell_type":"code","execution_count":null,"id":"9aef78a7-deb2-489e-b00a-7d5ebfda6d26","metadata":{"id":"9aef78a7-deb2-489e-b00a-7d5ebfda6d26","outputId":"5be37e17-1271-49a3-b9b7-e2a606d4c9bf","colab":{"referenced_widgets":["cef903f1c7d142ab9d0ec87545b5b52f"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cef903f1c7d142ab9d0ec87545b5b52f","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['good', 'poor', 'high', 'fair', 'low', 'excellent', 'bad', 'fine', 'moderate', 'decent', 'average', 'medium', 'acceptable']\n","[1781, 6460, 1880, 6534, 4482, 15129, 4319, 2691, 17768, 27189, 6588, 18350, 22691]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating [test_custom_videos.json]: 100%|██████████| 4/4 [00:00<00:00,  4.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Spearmanr 0.9486832980505139 Pearson 0.7544963861963276\n"]}],"source":["import sys\n","sys.path.append('/workspace/Q-Align')\n","from q_align.evaluate.vqa_eval import main\n","from types import SimpleNamespace\n","\n","args = SimpleNamespace(\n","    model_path=\"/workspace/Q-Align/checkpoints\",\n","    model_base=None,  # Set this to None if loading a full model\n","    device=\"cuda:0\",\n","    conv_mode=None,\n","    temperature=0.2,\n","    max_new_tokens=512,\n","    load_8bit=False,\n","    load_4bit=False,\n","    debug=False,\n","    image_aspect_ratio='pad'\n",")\n","\n","main(args)\n","# [\n","# {\n","#     \"img_path\": \"i2v.mp4\",\n","#     \"gt_score\": 2\n","#   },\n","#   {\n","#     \"img_path\": \"i2v (17).mp4\",\n","#     \"gt_score\": 0.7\n","#   },\n","#   {\n","#     \"img_path\": \"i2v (20).mp4\",\n","#     \"gt_score\": 1\n","#   },\n","#   {\n","#     \"img_path\": \"i2v (8).mp4\",\n","#     \"gt_score\": 1\n","#   }\n","# ]"]},{"cell_type":"code","execution_count":null,"id":"70a1e136-93b6-4c2a-9e2b-5e07bbe18a3a","metadata":{"id":"70a1e136-93b6-4c2a-9e2b-5e07bbe18a3a","outputId":"75b307e0-cbda-48b4-e681-4ff584869180","colab":{"referenced_widgets":["45b5ad2ca72d46efb96d82f6fc2e04ea"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45b5ad2ca72d46efb96d82f6fc2e04ea","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['good', 'poor', 'high', 'fair', 'low', 'excellent', 'bad', 'fine', 'moderate', 'decent', 'average', 'medium', 'acceptable']\n","[1781, 6460, 1880, 6534, 4482, 15129, 4319, 2691, 17768, 27189, 6588, 18350, 22691]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating [test_custom_videos.json]: 100%|██████████| 4/4 [00:00<00:00,  5.61it/s]"]},{"name":"stdout","output_type":"stream","text":["Spearmanr 0.23570226039551587 Pearson 0.04751143381455797\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import sys\n","sys.path.append('/workspace/Q-Align')\n","from q_align.evaluate.vqa_eval import main\n","from types import SimpleNamespace\n","\n","args = SimpleNamespace(\n","    model_path=\"/workspace/Q-Align/checkpoints\",\n","    model_base=None,  # Set this to None if loading a full model\n","    device=\"cuda:0\",\n","    conv_mode=None,\n","    temperature=0.2,\n","    max_new_tokens=512,\n","    load_8bit=False,\n","    load_4bit=False,\n","    debug=False,\n","    image_aspect_ratio='pad'\n",")\n","\n","main(args)\n","\n","# [\n","# {\n","#     \"img_path\": \"Mask_good.mp4\",\n","#     \"gt_score\": 1\n","#   },\n","#   {\n","#     \"img_path\": \"SpiderMan_Bad.mp4\",\n","#     \"gt_score\": 0.6\n","#   },\n","#   {\n","#     \"img_path\": \"SpiderMan_Bad.mp4\",\n","#     \"gt_score\": 5\n","#   },\n","#   {\n","#     \"img_path\": \"Mask_good.mp4\",\n","#     \"gt_score\": 5\n","#   }\n","# ]"]},{"cell_type":"code","execution_count":null,"id":"ad3bec82-c64d-498f-a164-d031ea51f427","metadata":{"id":"ad3bec82-c64d-498f-a164-d031ea51f427","outputId":"7a59e5aa-fc09-4eb2-df2d-9ff98112ac0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["['q-align-my-videos-lora', 'trainer_state.json', 'config.json', 'pytorch_model-00001-of-00004.bin', 'pytorch_model-00002-of-00004.bin', 'pytorch_model-00003-of-00004.bin', 'pytorch_model-00004-of-00004.bin', 'pytorch_model.bin.index.json', 'tokenizer_config.json', 'special_tokens_map.json', 'tokenizer.model', 'training_args.bin', 'preprocessor_config.json']\n"]}],"source":["import os\n","print(os.listdir('/workspace/Q-Align/checkpoints'))\n"]},{"cell_type":"code","execution_count":null,"id":"f73955cb-426e-41f8-9d9f-80e587f151ae","metadata":{"id":"f73955cb-426e-41f8-9d9f-80e587f151ae","outputId":"5ea98a66-f6ad-4db6-8edf-bbd021a917a2","colab":{"referenced_widgets":["c906e68cb61f4362a2a9c623230ed672"]}},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c906e68cb61f4362a2a9c623230ed672","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['good', 'poor', 'high', 'fair', 'low', 'excellent', 'bad', 'fine', 'moderate', 'decent', 'average', 'medium', 'acceptable']\n","[1781, 6460, 1880, 6534, 4482, 15129, 4319, 2691, 17768, 27189, 6588, 18350, 22691]\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating [test_custom_videos.json]: 100%|██████████| 2/2 [00:00<00:00,  6.77it/s]"]},{"name":"stdout","output_type":"stream","text":["Spearmanr 0.9999999999999999 Pearson 1.0\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import sys\n","sys.path.append('/workspace/Q-Align')\n","from q_align.evaluate.vqa_eval import main\n","from types import SimpleNamespace\n","\n","args = SimpleNamespace(\n","    model_path=\"/workspace/Q-Align/checkpoints\",\n","    model_base=None,  # Set this to None if loading a full model\n","    device=\"cuda:0\",\n","    conv_mode=None,\n","    temperature=0.2,\n","    max_new_tokens=512,\n","    load_8bit=False,\n","    load_4bit=False,\n","    debug=False,\n","    image_aspect_ratio='pad'\n",")\n","\n","main(args)\n","\n","# [\n","\n","#   {\n","#     \"img_path\": \"SpiderMan_Bad.mp4\",\n","#     \"gt_score\": 2\n","#   },\n","\n","#   {\n","#     \"img_path\": \"Mask_good.mp4\",\n","#     \"gt_score\": 5\n","#   }\n","# ]"]},{"cell_type":"code","execution_count":null,"id":"0a4a46cf-8b24-44df-9fce-85188909c43f","metadata":{"id":"0a4a46cf-8b24-44df-9fce-85188909c43f","outputId":"d7b9c4e8-ce4d-447b-c8d0-f9705bfc531b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting /workspace/Q-Align/q_align/evaluate/vqa_eval.py\n"]}],"source":["%%writefile /workspace/Q-Align/q_align/evaluate/vqa_eval.py\n","import argparse\n","import torch\n","\n","from q_align.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN\n","from q_align.conversation import conv_templates, SeparatorStyle\n","from q_align.model.builder import load_pretrained_model\n","from q_align.mm_utils import process_images, tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria\n","\n","from PIL import Image\n","\n","import requests\n","from PIL import Image\n","from io import BytesIO\n","from transformers import TextStreamer\n","\n","\n","from scipy.stats import spearmanr, pearsonr\n","\n","import json\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","import os\n","\n","def wa5(logits):\n","    import numpy as np\n","    logprobs = np.array([logits[\"excellent\"], logits[\"good\"], logits[\"fair\"], logits[\"poor\"], logits[\"bad\"]])\n","    probs = np.exp(logprobs) / np.sum(np.exp(logprobs))\n","    return np.inner(probs, np.array([1,0.75,0.5,0.25,0.]))\n","\n","\n","\n","def disable_torch_init():\n","    \"\"\"\n","    Disable the redundant torch default initialization to accelerate model creation.\n","    \"\"\"\n","    import torch\n","    setattr(torch.nn.Linear, \"reset_parameters\", lambda self: None)\n","    setattr(torch.nn.LayerNorm, \"reset_parameters\", lambda self: None)\n","\n","\n","def load_video(video_file):\n","    from decord import VideoReader\n","    vr = VideoReader(video_file)\n","\n","    # Get video frame rate\n","    fps = vr.get_avg_fps()\n","\n","    # Calculate frame indices for 1fps\n","    frame_indices = [int(fps * i) for i in range(int(len(vr) / fps))]\n","    frames = vr.get_batch(frame_indices).asnumpy()\n","    return [Image.fromarray(frames[i]) for i in range(int(len(vr) / fps))]\n","\n","\n","def main(args):\n","    # Model\n","    disable_torch_init()\n","\n","    model_name = get_model_name_from_path(args.model_path)\n","    tokenizer, model, image_processor, context_len = load_pretrained_model(args.model_path, args.model_base, model_name, args.load_8bit, args.load_4bit, device=args.device)\n","\n","\n","    import json\n","\n","\n","    image_paths = [\n","        \"/workspace/video_data/\"\n","        # \"playground/data/\",\n","        # \"playground/data/\",\n","        # \"playground/data/KoNViD_1k_videos/\",\n","        # \"playground/data/maxwell/\",\n","\n","    ]\n","\n","    json_prefix = \"playground/data/test_jsons/\"\n","    jsons = [\n","\n","        json_prefix + \"test_2.json\"\n","        # \"test_lsvq.json\",\n","        # json_prefix + \"test_lsvq_1080p.json\",\n","        # json_prefix + \"konvid.json\",\n","        # json_prefix + \"maxwell_test.json\",\n","    ]\n","\n","    os.makedirs(f\"results/{args.model_path}/\", exist_ok=True)\n","\n","\n","    conv_mode = \"mplug_owl2\"\n","\n","    inp = \"How would you rate the quality of this video?\"\n","\n","    conv = conv_templates[conv_mode].copy()\n","    inp =  inp + \"\\n\" + DEFAULT_IMAGE_TOKEN\n","    conv.append_message(conv.roles[0], inp)\n","    image = None\n","\n","    conv.append_message(conv.roles[1], None)\n","    prompt = conv.get_prompt() + \" The quality of the video is\"\n","\n","    toks = [\"good\", \"poor\", \"high\", \"fair\", \"low\", \"excellent\", \"bad\", \"fine\", \"moderate\",  \"decent\", \"average\", \"medium\", \"acceptable\"]\n","    print(toks)\n","    ids_ = [id_[1] for id_ in tokenizer(toks)[\"input_ids\"]]\n","    print(ids_)\n","\n","    input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to(args.device)\n","\n","    for image_path, json_ in zip(image_paths, jsons):\n","        with open(json_) as f:\n","            iqadata = json.load(f)\n","            prs, gts = [], []\n","            for i, llddata in enumerate(tqdm(iqadata, desc=\"Evaluating [{}]\".format(json_.split(\"/\")[-1]))):\n","                try:\n","                    try:\n","                        filename = llddata[\"img_path\"]\n","                    except:\n","                        filename = llddata[\"image\"]\n","                    llddata[\"logits\"] = defaultdict(float)\n","\n","                    image = load_video(image_path + filename)\n","                    def expand2square(pil_img, background_color):\n","                            width, height = pil_img.size\n","                            if width == height:\n","                                return pil_img\n","                            elif width > height:\n","                                result = Image.new(pil_img.mode, (width, width), background_color)\n","                                result.paste(pil_img, (0, (width - height) // 2))\n","                                return result\n","                            else:\n","                                result = Image.new(pil_img.mode, (height, height), background_color)\n","                                result.paste(pil_img, ((height - width) // 2, 0))\n","                                return result\n","                    image = [expand2square(img, tuple(int(x*255) for x in image_processor.image_mean)) for img in image]\n","                    image_tensor = image_processor.preprocess(image, return_tensors='pt')['pixel_values'].half().to(args.device)\n","\n","                    if True:\n","                        with torch.inference_mode():\n","                            output_logits = model(input_ids,\n","                                images=[image_tensor])[\"logits\"][:,-1]\n","                            for tok, id_ in zip(toks, ids_):\n","                                llddata[\"logits\"][tok] += output_logits.mean(0)[id_].item()\n","                            llddata[\"score\"] = wa5(llddata[\"logits\"])\n","                            # print(llddata)\n","                            prs.append(llddata[\"score\"])\n","\n","                            gts.append(llddata[\"gt_score\"])\n","                            print(llddata)\n","                            json_ = json_.replace(\"combined/\", \"combined-\")\n","                            with open(f\"results/{args.model_path}/{json_.split('/')[-1]}\", \"a\") as wf:\n","                                json.dump(llddata, wf)\n","\n","                    if i > 0 and i % 200 == 0:\n","                        print(spearmanr(prs,gts)[0], pearsonr(prs,gts)[0])\n","                except:\n","                    continue\n","            print(\"Spearmanr\", spearmanr(prs,gts)[0], \"Pearson\", pearsonr(prs,gts)[0])\n","\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--model-path\", type=str, default=\"q-future/one-align\")\n","    parser.add_argument(\"--model-base\", type=str, default=None)\n","    parser.add_argument(\"--device\", type=str, default=\"cuda:0\")\n","    parser.add_argument(\"--conv-mode\", type=str, default=None)\n","    parser.add_argument(\"--temperature\", type=float, default=0.2)\n","    parser.add_argument(\"--max-new-tokens\", type=int, default=512)\n","    parser.add_argument(\"--load-8bit\", action=\"store_true\")\n","    parser.add_argument(\"--load-4bit\", action=\"store_true\")\n","    parser.add_argument(\"--debug\", action=\"store_true\")\n","    parser.add_argument(\"--image-aspect-ratio\", type=str, default='pad')\n","    args = parser.parse_args()\n","    main(args)\n"]},{"cell_type":"code","execution_count":null,"id":"985e97bb-4e36-483e-a1af-be46c85be9be","metadata":{"id":"985e97bb-4e36-483e-a1af-be46c85be9be"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}